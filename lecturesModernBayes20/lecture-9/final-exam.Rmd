
---
title: "STA 360 Final Exam Review"
author: "Rebecca C. Steorts"
output: 
     beamer_presentation:
      includes: 
          in_header: custom2.tex
font-size: 8px
---



Final Exam
===

What are the big areas to study since Exam II? 

- Multivariate methods (normal and inverse wishart)
- Linear regression
- GLMs and exponential families
- Logistic regression


Course evalautions
===
 
- Please take 10-15 mintues to fill out the course evaluations for the course. 

- If students could also please fill out TA evaluations this would be very helpful. 

- If there is 100 percent response for these as well, there will be an extra incentive for the class!  


Review of Bayesian Methods (Module 1)
===

- Traditional inference 
- Bayes' Theorem
- Conjugate Distributions
- Marginal likelihood and posterior predictive distribution

\vspace*{1em}

\textbf{Module 1}: \url{https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-1/01-intro-to-Bayes.pdf}

Traditional inference 
===

Suppose I have data $x$ and I wish to estimate an **unknown, fixed** parameter $\theta$ using traditional (frequentist) inference. 

- I could use maximum likelihood estimation (MLE)
- I could find an unbiased estimator of $\theta.$

\vspace*{1em}

Goal of this course: we will instead assume $\theta$ is a **unknown, random variable**, and put a distribution $\theta.$ 

Bayes' Theorem
===

Recall Bayes' Theorem:

\begin{align}
p(\theta \mid x) &= \frac{p(\theta , x)}{p(x)} \\
&= \frac{p(x \mid \theta) p(\theta)}{p(x)} \\
&\propto p(x \mid \theta) p(\theta)  \\
\end{align}

This says that the **posterior** is proportional to the **likelihood** times the **prior**

Conjugacy
===

If the posterior distribution comes from the same family of distributions as the prior, we say that the prior and posterior are conjugate distributions.

\vspace*{1em}

More formally, the prior is called a conjugate family for the likelihood function.

\vspace*{1em}

Example: The **Beta prior** is conjugate to the **Bernoulli likelihood function.** 

Marginal likelihood and posterior predictive distribution
===

$p(x)$: marginal likelihood

- This is the normalizing constant in Bayes' theorem, that sometimes we cannot calculate.  

- When it cannot be calculated, this motivates the use of Monte Carlo methods (importance sampling, rejection sampling) or Markov monte Carlo methods (the Metropolis algorithm or Gibbs sampling).

 $p(x^{\text{new}} \mid x)$: posterior predictive distribution

- This is used for predicting a new observation based on observed data. 
 
Review of Decision Theory (Module 2)
===

- Loss functions
- Posterior risk
- Bayes rule
- Frequentist risk
- Integrated risk
- Admissibility

\textbf{Module 2}: \url{https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-2/02-intro-to-Bayes.pdf}


Loss function
===

- Let $\hat{\theta}$ is an estimator of $\theta$ (such as the MLE or Bayes estimator).
- A loss function $\ell(\theta, \hat{\theta})$ quantifies how far off the estimator is from the parameter of interest. 

Examples: 0-1 loss, squared error loss. 

Posterior risk
===

The posterior risk is defined as 

\begin{align}
\rho(\hat{\theta}, x) = E[\ell(\theta, \hat{\theta} \mid x]
\end{align}

Bayes rule
===

The Bayes rule under **squared error loss** is the posterior mean. 

Frequentist risk
===

The frequentist risk is defined as 

\begin{align}
R(\hat{\theta}, \theta) &= E[\ell(\theta, \hat{\theta}) \mid \theta] \\
&= \int \ell(\theta, \hat{\theta}) \textcolor{blue}{p(x \mid \theta)} \; dx
\end{align}

Integrated risk
===

\begin{align}
r(\hat{\theta}) &= E[\ell(\theta, \hat{\theta})] \\
&= \int \int \ell(\theta, \hat{\theta}) \textcolor{blue}{p(x \mid \theta) p(\theta)} \; dx \; d\theta
\end{align}

Admissibility
===

A decision rule is **admissible** so long as it's not being dominated everywhere. 

\vspace*{1em}

A decision rule is **inadmissible** is one that is dominated everywhere. 

\vspace*{1em}

Formally, $\hat{\theta}$ is admissible if there is **no other** $\hat{\theta^{\prime}}$ such that 

$$R(\theta, \hat{\theta^{\prime}}) \leq R(\theta, \hat{\theta}) \quad \text{for all} \quad \theta$$

and 

$$R(\theta, \hat{\theta^{\prime}}) \leq R(\theta, \hat{\theta})) \quad \text{for at least one} \quad \theta.$$

Review of Normal distribution (Module 3)
===

- Review of univariate normal distribution and key properties
- Re-parameterization normal distribution in terms of the precision
- Uniform prior
- Normal-Normal conjugacy

\vspace*{1em}

\textbf{Module 3}: \url{https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-3/03-normal-distribution.pdf}

Normal distribution
===

The normal distribution $\N(\mu,\sigma^2)$

- with mean $\mu\in\R$ and variance $\sigma^2 > 0$ - (standard deviation $\sigma =\sqrt{\sigma^2}$) has p.d.f.
$$\N(x\mid\mu,\sigma^2) =\frac{1}{\sqrt{2\pi\sigma^2}}\exp\Big(-\frac{1}{2\sigma^2}(x-\mu)^2\Big) $$
for $x\in\R$



Normal distribution (re-parametrization)
===

It is often more convenient to write the p.d.f.\ in terms of the **precision**, or inverse variance, $\lambda = 1/\sigma^2$ rather than the variance. 

\vspace*{1em}

In this parametrization, the p.d.f.\ is
$$\N(x\mid\mu,\lambda^{-1}) =\sqrt{\frac{\lambda}{2\pi}}\exp\big(-\tfrac{1}{2}\lambda (x-\mu)^2\big) $$
since $\sigma^2 = 1/\lambda =\lambda^{-1}$.

Uniform prior
===

We considered $X_{1:n} \mid \theta \stackrel{iid}{\sim} \N(x\mid\theta,\sigma^2),$

where $p(\theta) \propto 1,$ which is the uniform prior over the real line. 

\vspace*{1em}

We showed that $$\theta \mid x_{1:n} \sim \N( \bar{x}, \sigma^2/n).$$

Normal-Normal conjugacy
===

We considered the following model:

$$ X_1,\dotsc,X_n \mid \theta \iid\N(\theta,\lambda^{-1}). $$
Assume the precision $\lambda = 1/\sigma^2$ is known and fixed, and $\theta$ is given a $\N(\mu_0,\lambda_0^{-1})$ prior:
$$\theta \sim \N(\mu_0,\lambda_0^{-1})$$
i.e., $p(\theta) = \N(\theta\mid \mu_0,\lambda_0^{-1})$. This is sometimes referred to as a **Normal--Normal** model.

Normal-Normal conjugacy
===

We derived that 

$$p(\theta|x_{1:n}) =\N(\theta\mid M,L^{-1}),$$

where $$L =\lambda_0+ n\lambda \quad \text{and} \quad
M =\frac{\lambda_0\mu_0+\lambda\sum_{i = 1}^n x_i}{\lambda_0+ n\lambda}.$$


Review of Normal-Gamma model (Module 4)
===

- Consider our first hiearchical model with more than two levels


\vspace*{1em}

\textbf{Module 4}: \url{https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-4/04-normal-gamma.pdf}

Normal-Gamma model
===

Assume that the likelihood is

$X_1,\dotsc,X_n\mid \mu,\lambda \iid\N(\mu,\lambda^{-1})$ and assume **both**

- the mean $\mu$ and 
- the precision $\lambda= 1/\sigma^2$ are **unknown**. 

Given the likelihood, we place the following priors:
\begin{align*}
\bm\mu|\lambda \,\,&\sim \N(m,(c\lambda)^{-1})\\
\bm\lambda \,\,&\sim\Ga(a,b),
\end{align*}

where $m,c,a,b$ are known.

Normal-Gamma model
===

The joint p.d.f. of $\mu, \lambda$ can be written as 

$$ p(\mu,\lambda) = p(\mu|\lambda) p(\lambda) =\N(\mu\mid m,(c\lambda)^{-1})\Ga(\lambda\mid a,b) $$
which we  denote by 

$$\NormalGamma(\mu,\lambda\mid m,c,a,b).$$


Normal-Gamma model
===

We derived
\begin{align}\label{equation:NormalGamma-posterior}
\bm\mu,\bm\lambda|x_{1:n}\,\sim\,\NormalGamma(M,C,A,B)
\end{align}
i.e., $p(\mu,\lambda|x_{1:n}) =\NormalGamma(\mu,\lambda\mid M,C,A,B)$, where
\begin{align*}
    M & =\frac{c m +\sum_{i=1}^n x_i}{c + n}\\
    C & = c + n\\
    A & = a + n/2\\
    B & = b +\tfrac{1}{2}\big(c m^2-C M^2+\textstyle\sum_{i=1}^n x_i^2\big).
\end{align*}

Case study on IQ scores
===

- We considered a case study on IQ scores (for two groups) and talked about when we might consider the Normal-Gamma model over the Normal-Normal model. 

- This case study is a good one to review as it combines many different concepts in the course. 


Review of Monte Carlo and MCMC (Modules 5-7)
===

- Monte Carlo (naive, rejection, and importance sampling)
- Markov Chain Monte Carlo (Gibbs and Metropolis)

\textbf{Modules 5-7}:
\url{https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-5/05-monte-carlo.pdf

\url{https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-6/06-metropolis.pdf}

\url{https://github.com/resteorts/modern-bayes/tree/master/lecturesModernBayes20/lecture-7}




Goal of Monte Carlo and MCMC
===

Recall Bayes' Theorem:

\begin{align}
p(\theta \mid x) &= \frac{p(\theta , x)}{p(x)} \\
&= \frac{p(x \mid \theta) p(\theta)}{\textcolor{blue}{p(x)}}
\end{align}

As our models become more complex, we cannot compute $p(x),$ which calls for the use of needing to approximate the posterior distribution. 

Monte Carlo
===

- If were not faced with a high-dimensional problem, then we can resort to using Monte Carlo. This is appealing as it's simple, fast, and easy. 

- We illustrated this in the case study of the IQ scores in model 4, where we took some very simple Monte Carlo samples to help solve our case study. 

Markov Chain Monte Carlo
===

- If we are faced with high-dimensional problems, then we need to utilize MCMC (either Gibbs or Metropolis). 

- To use Gibbs, we must derive the full conditional distributions. Gibbs is appealing as it's relatively straight forward. 

- We typically turn to Metropolis last as it's more complex to implement. 

Key concepts 
===

- Understanding when Monte Carlo can be used and when it cannot. 

- Being able to work through Gibbs sampling problems. This means deriving the joint likelihood and full conditional distributions. 

- Understanding latent variable or data augmentation problems. 

- Understanding when you cannot use Gibbs and must use Metropolis (example: logistic regression on o-rings from Module 9).

Multivariate Normal 
===

- Multivariate Notation 
- Multivariate Normal and inverse Wishart
- MVN-MVN conjugacy
- MVN-inverseWishart conjugacy
- MVN-MVN-inverseWishart model 


\textbf{Module 8}:

\url:{https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-8/08-multivariate-norm.pdf}

\url{https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-8/08-missing-data.pdf}

Multivariate Notation
===

Assume that $\bm{y}_{p \times 1} \sim (\mu_{p \times 1}, \Sigma_{p \times p}).$

$$\bm{y}_{p \times 1}= \left( \begin{array}{c}
y_{1}\\
{y_{2}}\\
\vdots\\
y_{p}
\end{array} \right).$$



$$\bmu_{p \times 1}= \left( \begin{array}{c}
\mu_1\\
\mu_2\\
\vdots\\
\mu_p
\end{array} \right)
$$
$$
\sig_{p \times p} = Cov(\bm{y}) =
\left( \begin{array}{cccc}
\sigma_1^2 & \sigma_{12} & \ldots&  \sigma_{1p}\\
\sigma_{21} & \sigma_2^2 & \ldots& \sigma_{2p}\\
\vdots & \vdots & \ddots & \vdots \\
\sigma_{p1} & \sigma_{p2} &\ldots& \sigma_p^2
\end{array} \right).
$$

MVN-MVN
===

Suppose that $$\bm{y} = (y_1 \ldots y_n)^T \mid \theta \sim MVN(\theta, \Sigma). $$
Let $$\pi(\btheta) \sim MVN(\bmu, \Omega). $$

MVN-MVN
===

We derived that 

$$\btheta \mid \bm{y}, \Sigma \sim MVN(A_n^{-1}b_n, A_n^{-1}) = MVN(\mu_n, \Sigma_n),$$

where

$$A_n = A_o + A_1 = \Omega^{-1}+n\Sigma^{-1}$$ and $$b_n = b_o + b_1 = \Omega^{-1}\mu + \Sigma^{-1} n\bar{y}.$$

MVN-inverseWishart
===

We then considered the following model:

$$\bm{y} \mid \btheta, \Sigma \sim MVN(\btheta, \Sigma).$$ 
$$ \Sigma \sim \text{inverseWishart}(\nu_o, S_o^{-1}),$$


MVN-inverseWishart
===

We showed that 
$$\Sigma \mid \bm{y}, \btheta \sim \text{inverseWishart}(\nu_o + n, [S_o + S_\theta]^{-1} =: S_n),$$
where $S_\theta = \sum_i (\bm{y}_i - \btheta) (\bm{y}_i - \btheta)^T.$

MVN-MVN-inverseWishart
===

We  then considered the following hierachical model: 
$$\bm{y} \mid \btheta, \Sigma \sim MVN(\btheta, \Sigma).$$ 
$$ \btheta \sim MVN(\mu, \Omega)$$
$$ \Sigma \sim \text{inverseWishart}(\nu_o, S_o^{-1}),$$

where we used semi-conjuacy from the previous two derivations, which provide us with full conditional distributions. (Work through this on your own as an exercise for the final exam.)

- Derive the full joint to see why it's difficult to sample from. 
- Derive the full conditionals (Hint: use derivations we have done before.)
- Write out the Gibbs sampler (and you can check this as we did this in class).
- What diagnostics would you need to look at to make sure that your sampler has not failed to converge?


Linear Regression
===

- Setup
- Multivariate Linear Regression
- Multivariate Bayesian Linear Regression



\url{https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-9/9-linear-regression.pdf}

Setup
===

Let's assume that we have data points $(x_i, y_i)$ available for all  $i=1,\ldots,n.$

- $y$ is the response variable
\[  \by= \left( \begin{array}{c}
y_1\\
y_2\\
\vdots\\
y_n
\end{array} \right)_{n \times 1} \]

- $\bx_{i}$ is the $i$th row of the design matrix $X_{n \times p}.$

Consider the regression coefficients

\[  \bbeta = \left( \begin{array}{c}
\beta_{1}\\
\beta_{2}\\
\vdots\\
\beta_{p}
\end{array} \right)_{p \times 1} \]

Multivariate Linear Regression
===

The Normal regression model specifies that

- $E[Y\mid \bx_i]$ is linear and
- the sampling variability around the mean is independently and identically (iid) drawn from a normal distribution

\begin{align}
Y_i &= \bbeta^T \bx_i + \bm{\epsilon}_i\\
\epsilon_1,\ldots,\epsilon_n &\stackrel{iid}{\sim} \text{Normal}(0,\sigma^2)
\end{align}

This implies $Y_i \mid \bbeta, \bx_i \sim \text{Normal}(\bbeta^T \bx_i,\sigma^2).$

We can re-write this as

$$\by \mid X,\bbeta, \sigma^2 \sim \text{MVN}( X\bbeta, \sigma^2 I_p).$$

Multivariate Bayesian Linear Regression
===

Let 
\begin{align}
\bm{y} &\mid \bbeta \sim \text{MVN}(X \bbeta, \sigma^2 I)\\
\bbeta &\sim \text{MVN}(\bbeta_0, \Sigma_0)
\end{align}

We derived (exercise 3)
$$\bbeta \mid \bm{y}, X \sim \text{MVN}(\bbeta_n, \Sigma_n), \; \text{where}$$
\begin{align*}
\bbeta_n &= E[\bbeta\ \mid \bm{y}, \bX, \sigma^2] = (\Sigma_o^{-1} + (X^TX)/\sigma^2)^{-1}
(\Sigma_o^{-1}\bbeta_0 + \bX^T\bm{y}/\sigma^2) \\
\Sigma_n &= \text{Var}[\bbeta \mid \bm{y}, X, \sigma^2] = (\Sigma_o^{-1} + (X^TX)/\sigma^2)^{-1}
\end{align*}

Remark: If $\Sigma_o^{-1} << (X^TX)^{-1}$ then $\bbeta_n \approx \hat{\bbeta}_{ols}$

If $\Sigma_o^{-1} >> (X^TX)^{-1}$ then $\bbeta_n \approx \bbeta_{0}$

The g-prior
===

To improve our model by doing the **least amount of calculus**, we can put a \emph{g-prior} on $\bbeta$ (not $\bbeta_0).$

The g-prior on $\bbeta$ has the following form: 
$$ \bbeta \mid \bX, \sigma^2  \sim MVN(0, g\; \sigma^2 (\bX^T\bX)^{-1}),$$
where $g$ is a constant, such as $g=n.$


It can be shown that (Zellner, 1986):

1. g shrinks the coefficients and can prevent overfitting to the data
2. if $g = n$, then as n increases, inference approximates that using $\hat{\beta}_{ols}$

The g-prior
===
Under the g-prior, it follows that
\begin{align}
\bbeta_n &= E[\bbeta\ \mid \bm{y}, \bX, \sigma^2]  \\
&= \left(\frac{X^TX}{g \sigma^2} + \frac{X^TX}{\sigma^2}\right)^{-1} \frac{X^Ty}{\sigma^2} \\
&= \frac{g}{g+1} (X^TX)^{-1} X^Ty
= \frac{g}{g+1} \hat{\beta}_{ols}
\end{align}

\begin{align}
\Sigma_n &= \text{Var}[\bbeta \mid \bm{y}, \bX, \sigma^2] \\
&= \left(\frac{X^TX}{g \sigma^2} + \frac{X^TX}{\sigma^2}\right)^{-1}
=\frac{g}{g+1} \sigma^2 (X^TX)^{-1} \\
&= \frac{g}{g+1} \Var[\hat{\beta}_{ols}]
\end{align}

Logistic Regression
===

- Generalized Linear Models
- Exponential Families

\url{https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-9/9-logistic-regression.pdf}

Generalized Linear Models
===

We turn to **generalized linear models** when 

- the range of $y_i$ is restricted
- the variance of $y_i$ depends on the mean

Exponential Families 
===

In a GLM, pdfs or pmfs can be shown to be an exponential family using equation~\ref{eqn:exponential}.

\begin{align}
\label{eqn:exponential}
f(y; \theta, \phi) = \exp\left\{ \frac{y\theta - b(\theta)}{a(\phi)} + c(y,\phi) \right\},
\end{align}

It's important to identify the parameters of the exponential family, namely: 

$$\theta, \; \phi, \; a(\phi),\; b(\theta),\; c(y,\phi).$$


Generalized Linear Models
===

We assume $\mu = E[Y\mid X]$ and our goal is to estimate $\mu.$

- The **systematic component** relates $\eta$ to $X.$ 

In a GLM, $$\eta = \beta^T X = \beta_1 X_1 + \ldots \beta_p X_p$$

- The **link component** connects the **random** and **systematic components**, via a link function $g(\mu) = \eta(X).$ 

- The link function provides a connection between $\mu = E[Y\mid X]$ and $\eta.$ 

Bernoulli Example
===

Suppose $Y \in \{ 0, 1\}$  and 
$$Y\mid X \stackrel{iid}{\sim} \text{Bernoulli}(p).$$

We showed that $Y \mid X$ is in the exponential family, where 

\begin{align}
f(y) &= \exp\{
y \log ({\frac{p}{1-p}}) + \log(1-p) + 0
\} 
\end{align}

- The natural parameter is $\theta = \log \dfrac{p}{1-p}.$

- The mean is $\mu = p,$ which implies that
$p = e^{\theta}/(1 + e^{\theta}).$

- This implies $b(\theta) = -\log(1-p) = -\log(1 + e^{\theta}).$

- There is no dispersion parameter, so $a(\phi) = 1$ and $c(y,\phi) = 0.$


Bernoulli Example (Continued)
===

The link function is $$g(\mu) = \log(\frac{\mu}{1-\mu})$$ such that we model $$\log(\frac{\mu}{1-\mu}) = \text{logit}(\mu)= \beta^TX.$$

This is known as **logistic regression**, which is a GLM with the **logit link**.

Logistic regression
===

Our motivation for logistic regression was the Challenger case study, where 

- the response is the damage to the o-ring (in each shuttle launch). 

- the covariate is the temperature (F) in each shuttle launch. 

Logistic regression
===

- Let $p_i$ be the probability that an o-ring $i$ fails. 

- The corresponding **odds of failure** is $$\frac{p_i}{1-p_i}.$$
The response 

\begin{align}
Y_i \mid p_i &\sim \text{Bernoulli}(p_i)
\end{align}
for $i=1,\ldots,n.$

The logistic GLM writes that the logit of the probability  $p_i$
as linear function of the predictor variable(s) $x_i$: 

\begin{align}
\text{logit}(p_i)  &:= \log(\frac{p_i}{1-p_i}) = \beta_0 + \beta_1x_i.
\end{align}


Intuition of Model
===

We assume our 23 data points are **conditionally independent**. 

$$\text{Pr(failure = 1)} = \frac{\exp\{\beta_0 + \beta_1 \times \text{temp}\}}{1+ \exp\{\beta_0 + \beta_1 \times \text{temp}\}}$$
\begin{align}
&\text{failure}_1,\ldots, \text{failure}_{23} \mid \beta_0, \beta_1, \text{temp}_1,\ldots, \text{temp}_{23} \\
& \sim 
\prod_i 
\left(\frac{\exp\{\beta_0 + \beta_1 \times \text{temp}_i\}}{1+ \exp\{\beta_0 + \beta_1 \times \text{temp}_i\}}\right)^{\text{failure}_i} \\
&\times
\left(\frac{1}{1+ \exp\{\beta_0 + \beta_1 \times \text{temp}_i\}}\right)^{\text{1-failure}_i}
\end{align}

Bayesian Logistic Regression
===

For $i=1,\ldots,n$

\begin{align}
Y_i \mid p_i &\sim \text{Bernoulli}(p_i)\\
\text{logit}(p_i) &:= \log(\frac{p_i}{1-p_i}) = \beta_0 + \beta_1x_i.
\end{align}




\begin{align}
\beta_0 &\sim \text{Normal}(0,1000) \\
\beta_1 &\sim \text{Normal}(0,1000) 
\end{align}

How would you solve this computationally? 

Exam Resources
===

1. **Exams 2020** \url{https://github.com/resteorts/modern-bayes/tree/master/exercises/exams-fall-2020}
2. **Final Exam Practice Problems** \url{https://github.com/resteorts/modern-bayes/tree/master/exercises/final-exam}
3. **Final Exam Exercises** \url{https://github.com/resteorts/modern-bayes/tree/master/exercises/exercises-final-exam}


Exam Resources
===

1. **Exam I Exercises** \url{https://github.com/resteorts/modern-bayes/tree/master/exercises/exercises-exam-one}
2. **Exam II Exercises** \url{https://github.com/resteorts/modern-bayes/tree/master/exercises/exercises-exam-two}
3. **Additional Practice Exercises**
\url{https://github.com/resteorts/modern-bayes/blob/master/exercises/additional-practice-problems/practice-problems.pdf}
4. **Multiple Choice Questions** \url{https://github.com/resteorts/modern-bayes/tree/master/exercises/multiple-choice}









